{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple ways to do sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Import libraries.\n",
    "import pandas as pd\n",
    "from py_modules.ml_utils import *\n",
    "\n",
    "#! Import training and test data.\n",
    "train_df = pd.read_csv(\"cleaned_aclImdb/train.csv\")\n",
    "test_df = pd.read_csv(\"cleaned_aclImdb/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for NB classifier with BOW vectorizer:\n",
      "\tRuntime: 4.58 seconds\n",
      "\tAccuracy: 82.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.87      0.83     12500\n",
      "         pos       0.86      0.77      0.81     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.83      0.82      0.82     25000\n",
      "weighted avg       0.83      0.82      0.82     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for NB classifier with TFIDF vectorizer:\n",
      "\tRuntime: 5.57 seconds\n",
      "\tAccuracy: 83.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.88      0.84     12500\n",
      "         pos       0.87      0.79      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Bag-of-Words model.\n",
    "bow_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bow\", classifier_type=\"nb\"\n",
    ")\n",
    "\n",
    "#! Using a TF-IDF model.\n",
    "tfidf_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"tfidf\", classifier_type=\"nb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for NB classifier with UNIGRAM vectorizer:\n",
      "\tRuntime: 5.49 seconds\n",
      "\tAccuracy: 82.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.87      0.83     12500\n",
      "         pos       0.86      0.77      0.81     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.83      0.82      0.82     25000\n",
      "weighted avg       0.83      0.82      0.82     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for NB classifier with BIGRAM vectorizer:\n",
      "\tRuntime: 14.54 seconds\n",
      "\tAccuracy: 84.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.90      0.85     12500\n",
      "         pos       0.88      0.79      0.83     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.85      0.84      0.84     25000\n",
      "weighted avg       0.85      0.84      0.84     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for NB classifier with TRIGRAM vectorizer:\n",
      "\tRuntime: 18.51 seconds\n",
      "\tAccuracy: 74.08%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.71      0.81      0.76     12500\n",
      "         pos       0.78      0.67      0.72     12500\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.75      0.74      0.74     25000\n",
      "weighted avg       0.75      0.74      0.74     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Unigram model.\n",
    "unigram_nb_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"unigram\", classifier_type=\"nb\"\n",
    ")\n",
    "\n",
    "#! Using a Bigram model.\n",
    "bigram_nb_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bigram\", classifier_type=\"nb\"\n",
    ")\n",
    "\n",
    "#! Using a Trigram model.\n",
    "trigram_nb_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"trigram\", classifier_type=\"nb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for NB classifier with UNIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 5.60 seconds\n",
      "\tAccuracy: 83.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.88      0.84     12500\n",
      "         pos       0.87      0.79      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for NB classifier with BIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 15.14 seconds\n",
      "\tAccuracy: 85.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.90      0.86     12500\n",
      "         pos       0.89      0.80      0.84     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for NB classifier with TRIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 18.85 seconds\n",
      "\tAccuracy: 74.10%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.72      0.80      0.75     12500\n",
      "         pos       0.77      0.68      0.73     12500\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.74      0.74      0.74     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Unigram model with TF-IDF.\n",
    "unigram_nb_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"unigram-tfidf\", classifier_type=\"nb\"\n",
    ")\n",
    "\n",
    "#! Using a Bigram model with TF-IDF.\n",
    "bigram_nb_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bigram-tfidf\", classifier_type=\"nb\"\n",
    ")\n",
    "\n",
    "#! Using a Trigram model with TF-IDF.\n",
    "trigram_nb_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"trigram-tfidf\", classifier_type=\"nb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for LR classifier with BOW vectorizer:\n",
      "\tRuntime: 12.79 seconds\n",
      "\tAccuracy: 86.31%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.87      0.86     12500\n",
      "         pos       0.87      0.86      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for LR classifier with TFIDF vectorizer:\n",
      "\tRuntime: 7.93 seconds\n",
      "\tAccuracy: 87.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.88      0.88     12500\n",
      "         pos       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Bag-of-Words model.\n",
    "bow_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bow\", classifier_type=\"lr\"\n",
    ")\n",
    "\n",
    "#! Using a TF-IDF model.\n",
    "tfidf_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"tfidf\", classifier_type=\"lr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for LR classifier with UNIGRAM vectorizer:\n",
      "\tRuntime: 13.15 seconds\n",
      "\tAccuracy: 86.31%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.87      0.86     12500\n",
      "         pos       0.87      0.86      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for LR classifier with BIGRAM vectorizer:\n",
      "\tRuntime: 29.45 seconds\n",
      "\tAccuracy: 83.79%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.83      0.84     12500\n",
      "         pos       0.83      0.85      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for LR classifier with TRIGRAM vectorizer:\n",
      "\tRuntime: 43.33 seconds\n",
      "\tAccuracy: 70.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.54      0.65     12500\n",
      "         pos       0.66      0.88      0.75     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.74      0.71      0.70     25000\n",
      "weighted avg       0.74      0.71      0.70     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Unigram model.\n",
    "unigram_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"unigram\", classifier_type=\"lr\"\n",
    ")\n",
    "\n",
    "#! Using a Bigram model.\n",
    "bigram_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bigram\", classifier_type=\"lr\"\n",
    ")\n",
    "\n",
    "#! Using a Trigram model.\n",
    "trigram_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"trigram\", classifier_type=\"lr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for LR classifier with UNIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 8.40 seconds\n",
      "\tAccuracy: 87.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.88      0.88     12500\n",
      "         pos       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for LR classifier with BIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 26.89 seconds\n",
      "\tAccuracy: 83.55%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.83      0.83     12500\n",
      "         pos       0.83      0.84      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for LR classifier with TRIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 23.95 seconds\n",
      "\tAccuracy: 74.14%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.72      0.74     12500\n",
      "         pos       0.73      0.76      0.75     12500\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.74      0.74      0.74     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Unigram model with TF-IDF.\n",
    "unigram_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"unigram-tfidf\", classifier_type=\"lr\"\n",
    ")\n",
    "\n",
    "#! Using a Bigram model with TF-IDF.\n",
    "bigram_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bigram-tfidf\", classifier_type=\"lr\"\n",
    ")\n",
    "\n",
    "#! Using a Trigram model with TF-IDF.\n",
    "trigram_lr_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"trigram-tfidf\", classifier_type=\"lr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for SVM classifier with BOW vectorizer:\n",
      "\tRuntime: 13.15 seconds\n",
      "\tAccuracy: 84.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.86      0.85     12500\n",
      "         pos       0.85      0.83      0.84     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for SVM classifier with TFIDF vectorizer:\n",
      "\tRuntime: 4.87 seconds\n",
      "\tAccuracy: 86.93%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.88      0.87     12500\n",
      "         pos       0.88      0.86      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Bag-of-Words model.\n",
    "bow_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bow\", classifier_type=\"svm\"\n",
    ")\n",
    "\n",
    "#! Using a TF-IDF model.\n",
    "tfidf_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"tfidf\", classifier_type=\"svm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for SVM classifier with UNIGRAM vectorizer:\n",
      "\tRuntime: 10.23 seconds\n",
      "\tAccuracy: 84.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.86      0.85     12500\n",
      "         pos       0.85      0.83      0.84     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for SVM classifier with BIGRAM vectorizer:\n",
      "\tRuntime: 31.32 seconds\n",
      "\tAccuracy: 83.57%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.82      0.83     12500\n",
      "         pos       0.83      0.85      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for SVM classifier with TRIGRAM vectorizer:\n",
      "\tRuntime: 49.32 seconds\n",
      "\tAccuracy: 70.62%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.53      0.64     12500\n",
      "         pos       0.65      0.88      0.75     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.73      0.71      0.70     25000\n",
      "weighted avg       0.73      0.71      0.70     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Unigram model.\n",
    "unigram_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"unigram\", classifier_type=\"svm\"\n",
    ")\n",
    "\n",
    "#! Using a Bigram model.\n",
    "bigram_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bigram\", classifier_type=\"svm\"\n",
    ")\n",
    "\n",
    "#! Using a Trigram model.\n",
    "trigram_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"trigram\", classifier_type=\"svm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation for SVM classifier with UNIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 4.93 seconds\n",
      "\tAccuracy: 86.93%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.88      0.87     12500\n",
      "         pos       0.88      0.86      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for SVM classifier with BIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 12.88 seconds\n",
      "\tAccuracy: 84.97%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.85      0.85     12500\n",
      "         pos       0.85      0.85      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model evaluation for SVM classifier with TRIGRAM-TFIDF vectorizer:\n",
      "\tRuntime: 16.13 seconds\n",
      "\tAccuracy: 74.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.73      0.74     12500\n",
      "         pos       0.74      0.75      0.74     12500\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.74      0.74      0.74     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#! Using a Unigram model with TF-IDF.\n",
    "unigram_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"unigram-tfidf\", classifier_type=\"svm\"\n",
    ")\n",
    "\n",
    "#! Using a Bigram model with TF-IDF.\n",
    "bigram_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"bigram-tfidf\", classifier_type=\"svm\"\n",
    ")\n",
    "\n",
    "#! Using a Trigram model with TF-IDF.\n",
    "trigram_svm_classifier = train_and_evaluate_model(\n",
    "    train_df, test_df, vectorizer_type=\"trigram-tfidf\", classifier_type=\"svm\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
